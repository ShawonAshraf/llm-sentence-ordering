{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = load_dataset(os.getenv(\"HF_HUB_DATASET_NAME\"))\n",
    "assert dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the first 32 examples\n",
    "sampled_dataset = dataset_name['train'].select(range(2))\n",
    "len(sampled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are given 5 sentences from a story in a shuffled order. \n",
    "Each sentence has a serial number assoiciated with it. \n",
    "You can find the serial number at the beginning of each sentence, for example: 0. <sentence>.\n",
    "The serial numbers start from 0 and ends at 4.\n",
    "Your task is to predict the correct order of sentences which would resemble the original story and then return the serial numbers as a comma separated string.\n",
    "\n",
    "#IMPORTANT\n",
    "There are exactly five sentences. \n",
    "You should only return the serial numbers as a comma separated string.\n",
    "\"\"\"\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    api_key=\"token-abc123\",\n",
    "    base_url=os.getenv(\"VLLM_ENDPOINT_URL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbaf364084d4d72b777ca8e7134cd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "formatted_inputs = []\n",
    "for _, data in tqdm(enumerate(sampled_dataset)):\n",
    "    ins = \"\"\n",
    "    for idx, sent in enumerate(data[\"shuffled_sentences\"]):\n",
    "        ins += f\"{idx}. {sent}\\n\"\n",
    "    formatted_inputs.append(ins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0. They got themselves and Dan on a diet.\\n1. Dan's parents were overweight.\\n2. Dan was overweight as well.\\n3. His parents understood and decided to make a change.\\n4. The doctors told his parents it was unhealthy.\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To predict the correct order of sentences, let's analyze the given sentences:\n",
      "\n",
      "- Sentence 0 mentions Dan and his family going on a diet, implying that there was a problem that needed to be addressed.\n",
      "- Sentence 1 and 2 provide the reason for the diet, which is that Dan's parents and Dan himself were overweight.\n",
      "- Sentence 3 suggests that Dan's parents are taking action to address the issue.\n",
      "- Sentence 4 provides a reason for the parents' decision to make a change, which is that the doctors told them it was unhealthy.\n",
      "\n",
      "Based on this analysis, the correct order of sentences would be:\n",
      "\n",
      "0. They got themselves and Dan on a diet.\n",
      "1. Dan's parents were overweight.\n",
      "2. Dan was overweight as well.\n",
      "3. His parents understood and decided to make a change.\n",
      "4. The doctors told his parents it was unhealthy.\n",
      "\n",
      "The serial numbers as a comma-separated string would be: 0,1,2,3,4\n",
      "[1, 2, 4, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "response =  await client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": formatted_inputs[0]}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(sampled_dataset[0][\"gold_order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To predict the correct order of sentences, let's analyze the given sentences:\n",
      "\n",
      "- Sentence 4 mentions that Carrie had just learned how to ride a bike, which suggests that the story is about her learning to ride a bike.\n",
      "- Sentence 0 mentions Carrie sneaking rides on her sister's bike, which implies that she doesn't have a bike of her own, which is mentioned in sentence 3.\n",
      "- Sentence 2 mentions Carrie crashing into a wall, which is likely to happen after she has gained some experience and confidence in riding the bike.\n",
      "- Sentence 1 mentions Carrie getting a deep gash on her leg, which is likely to happen during her early attempts to ride the bike.\n",
      "\n",
      "Considering these points, the correct order of sentences would be:\n",
      "\n",
      "4. Carrie had just learned how to ride a bike.\n",
      "0. Carrie would sneak rides on her sister's bike.\n",
      "3. She didn't have a bike of her own.\n",
      "1. The bike frame bent and Carrie got a deep gash on her leg.\n",
      "2. She got nervous on a hill and crashed into a wall.\n",
      "\n",
      "The serial numbers as a comma-separated string would be: 4,0,3,1,2\n",
      "[4, 3, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "response = await client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": formatted_inputs[1]}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(sampled_dataset[1][\"gold_order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using instructor\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class PredictionResult(BaseModel):\n",
    "    predicted_order: List[int] = Field(\"A list of integers in the range 0 upto 4, which contains the serial numbers of sentences in the correct order.\")\n",
    "\n",
    "\n",
    " \n",
    "iclient = instructor.from_openai(OpenAI(\n",
    "    api_key=\"token-abc123\",\n",
    "    base_url=os.getenv(\"VLLM_ENDPOINT_URL\")\n",
    "))\n",
    "system_message = \"\"\"\n",
    "You are given 5 sentences from a story in a shuffled order. \n",
    "Each sentence has a serial number assoiciated with it. \n",
    "You can find the serial number at the beginning of each sentence, for example: 0. <sentence>.\n",
    "The serial numbers start from 0 and ends at 4.\n",
    "Your task is to predict the correct order of sentences which would resemble the original story and then return the serial numbers as a list of integers, which contain the serial numbers.\n",
    "\n",
    "#IMPORTANT\n",
    "There are exactly five sentences. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_order=[0, 3, 4, 1, 2]\n",
      "[1, 2, 4, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "response = iclient.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": formatted_inputs[0]}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    response_model=PredictionResult,\n",
    ")\n",
    "\n",
    "\n",
    "print(response)\n",
    "print(sampled_dataset[0][\"gold_order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_order=[4, 0, 1, 2, 3]\n",
      "[4, 3, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "response = iclient.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": formatted_inputs[1]}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    response_model=PredictionResult,\n",
    ")\n",
    "\n",
    "\n",
    "print(response)\n",
    "print(sampled_dataset[1][\"gold_order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=np.float64(0.19999999999999998), pvalue=np.float64(0.8166666666666667))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html\n",
    "kendalltau(x=sampled_dataset[1][\"gold_order\"], y=response.predicted_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def overlapping_accuracy(gold, predicted):\n",
    "    assert len(gold) == len(predicted)\n",
    "    \n",
    "    overlaps = 0\n",
    "    for idx in range(len(gold)):\n",
    "        if gold[idx] == predicted[idx]:\n",
    "            overlaps += 1\n",
    "            \n",
    "    return overlaps / len(gold)\n",
    "\n",
    "\n",
    "overlapping_accuracy(\n",
    "    sampled_dataset[1][\"gold_order\"], response.predicted_order)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
